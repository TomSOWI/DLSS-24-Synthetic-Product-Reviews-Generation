# **Replication material and Appendix for the paper "Synthetic Product Review Generation for Market Analysis: A GPT-2 and LLaMA 3 Approach"**
**Description:** This repository contains the replication materials and the Appendix for our final project for the course "Deep Learning for the Social Sciences" (SuSe 2024) at the University of Konstanz.

**Authors:** Carl George-Lembach, Tom Klotz, Julia Schlei√üheimer, and Valentin Velev

**Aim of the Project:** Generate synthetic product reviews using GPT-2 Medium and LLaMA 3 8B, compare them with real product reviews, and assess their suitablility for market analysis

**Main Dataset:** Amazon fashion category from McAuley Lab's Amazon Reviews dataset (available [here](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023))

## Appendix
The Appendix for our paper is available in the file [DLSS-24-Final-Project-Group-3-NLP-Appendix.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/DLSS-24-Final-Project-Group-3-NLP-Appendix.pdf) :page_facing_up:.

## Fine-Tuned GPT-2 Medium
Our fine-tuned GPT-2 Medium model is available on [Hugging Face](https://huggingface.co/TomData/GPT2-review) :hugs:.

Nore that since we used PyTorch to fine-tune GPT-2 Medium, the Inference API on Hugging Face does not work.

## Data
In the folder [Data](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/tree/main/Data) :bar_chart:, we have made available our main datasets. The remaining datasets (from the ETL Notebook) are available on [Synology Cloud](https://T34278926.quickconnect.to/d/s/zpVAefWwFEYfIhTRTc0RfJ1h4rXzh6kJ/7VRz2eFaGxxjR11Xtygq65lAszhLPaIi-7LuAL9qlnQs) :cloud:. Below you will find a brief overview of all the data files:

**Main Datasets:**

* [preprocessed_reviews.parquet](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/tree/main/Data/preprocessed_reviews.parquet): Contains our preprocessed data with 100,000 Amazon fashion item reviews. **This is the data we used for our preliminary data analysis and for fine-tuning our GPT-2 Medium model.**
* [preprocessed_reviews_topics.parquet](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/tree/main/Data/preprocessed_reviews_topics.parquet): Contains our preprocessed data with a topic assigned to each review achieved by using BERTopic
* [topic_modeling_results.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/tree/main/Data/topic_modeling_results.csv): Contains the results of BERTopic on the 100,000 Amazon product reviews

**Generated Reviews:**

* **GPT-2**
  * [gpt-2_synthetic_reviews.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/gpt-2_synthetic_reviews.csv): Contains the sample of 10,000 synthetic product reviews generated by our fine-tuned GPT-2 Medium and the perplexity scores for each synthetic product review. **This is the data we used for our statistical evaluation.**
  * [gpt-2_synthetic_reviews_human_eval_sample.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/gpt-2_synthetic_reviews_human_eval_sample.csv): Contains a random sample of 100 synthetic product reviews generated by our fine-tuned GPT-2 Medium for human evaluation and the perplexity scores for each synthetic product review. **This is the data we used for our human evaulation.**
  * [gpt-2_tested_prompts.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/gpt-2_tested_prompts.csv): Contains some of our the prompts we tested while prompt engineering our GPT-2 prompt, as well as their outputs and their perplexities
* **LLaMA 3**
  * [llama-3_synthetic_reviews_5k_positive.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_5k_positive.csv): Contains the sample of 5,000 synthetic product reviews generated using the positive prompt for LLaMA 3
  * [llama-3_synthetic_reviews_5k_negative.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_5k_negative.csv): Contains the sample of 5,000 synthetic product reviews generated using the negative prompt for LLaMA 3
  * [llama-3_synthetic_reviews.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews.csv): Contains the sample of 10,000 synthetic product reviews generated by Llama 3 8B and the perplexity scores for each synthetic product review
  * [llama-3_synthetic_reviews_split.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_split.csv): Contains the same data as [llama-3_synthetic_reviews.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews.csv) but with only one synthetic product review per row. **This is the data we used for our statistical evaluation.**
  * [llama-3_synthetic_reviews_human_eval_sample.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_human_eval_sample.csv): Contains a random sample of 100 synthetic product reviews generated by our fine-tuned GPT-2 Medium for human evaluation and the perplexity scores for each synthetic product review
  * [llama-3_synthetic_reviews_human_eval_sample_split.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_human_eval_sample_split.csv): Contains the same data as [llama-3_synthetic_reviews_human_eval_sample.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_human_eval_sample.csv) but with the split reviews. **This is the data we used for our human evaluation.**
  * [llama-3_tested_prompts.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_tested_prompts.csv): Contains some of our the prompts we tested while prompt engineering our LLaMA prompt, as well as their outputs and their perplexities

**Evaluation:**
* [human_evaluation_rater1.xlsx](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/human_evaluation_rater1.xlsx): Contains the results from rater 1 for the human evaluation
* [human_evaluation_rater2.xlsx](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/human_evaluation_rater2.xlsx): Contains the results from rater 2 for the human evaluation
* [human_evaluation_rater3.xlsx](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/human_evaluation_rater3.xlsx): Contains the results from rater 3 for the human evaluation
* [human_evaluation_rater4.xlsx](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/human_evaluation_rater4.xlsx): Contains the results from rater 4 for the human evaluation
* [market_analysis_rater1.xlsx](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/market_analysis_rater1.xlsx): Contains the results from rater 1 for our market analysis
* [market_analysis_rater2.xlsx](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/market_analysis_rater2.xlsx): Contains the results from rater 2 for our market analysis
* [topic_modeling_market_analysis.zip](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/topic_modeling_market_analysis.zip): Contains the results of the topic models for our market analysis. Note: the code from [topic_modeling.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/topic_modeling.ipynb) was re-used with minor changes (changed nr_topics from 15 to 10) to create all csv files inside the zip file.
* [real_reviews_10k_sample.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/real_reviews_10k_sample.csv): Contains the sample of 10,000 real product reviews used for the statistical evaluation and market analysis. **This data was used for our statistical evaluation and our sentiment analysis in the market analysis.**
* [real_reviews_tshirt_sample.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/real_reviews_tshirt_sample.csv): Contains the sample of 100 real product reviews about T-shirts used in the first part of the market analysis
* [real_reviews_10k_sample_sentiment.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/real_reviews_10k_sample_sentiment.csv): Contains the same data as [real_reviews_10k_sample.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/real_reviews_10k_sample.csv) but with a topic assigned to each review achieved by using BERTopic
* [gpt-2_synthetic_reviews_sentiment.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/gpt-2_synthetic_reviews_sentiment.csv): Contains the same data as [gpt-2_synthetic_reviews.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/gpt-2_synthetic_reviews.csv) but with a topic assigned to each review achieved by using BERTopic
* [llama-3_synthetic_reviews_split_sentiment.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_split_sentiment.csv): Contains the same data as [llama-3_synthetic_reviews_split.csv](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Data/llama-3_synthetic_reviews_split.csv) but with a topic assigned to each review achieved by using BERTopic

## Notebooks
In the folder [Notebooks](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/tree/main/Notebooks) :notebook:, are all the Jupyter Notebooks we used for all our computation, analysis, and visualization, including the main Notebooks, the Notebooks used for classification, the Notebooks used for synthetic product review generation, and the Notebooks used for the analysis of the product reviews. Below you will find a brief overview of all the Jupyter Notebooks:

**Main Notebooks:**
* [ETL.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/ETL.ipynb): Notebook for data preprocessing / extract-transform-load (ETL) pipeline, including:
  * Data acquisition
  * Data cleaning
  * Preparation of final dataset
* [EDA.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/EDA.ipynb): Notbook for exploratory data analysis (EDA), including:
  * Average length of reviews and standard deviation of review length
  * Histogram of review length distribution
  * Rating distribution (overall and by sentiment)
  * Word clouds (overall, by sentiment, and by rating)
  * Topic modeling using BERTopic
* [gpt-2_fine-tune.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/gpt-2_fine-tune.ipynb): Notebook for fine-tuning GPT-2. Note that the fine-tuning with 100,000 reviews takes roughly 2-3 days using two NVIDIA A40 GPUs (48 GB).

**Notebooks for Classification:**
* [sentiment.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/sentiment.ipynb): Notebook for classifying the Amazon fashion item reviews to randomly sample by sentiment using SiEBERT (see paper for more information). This Notebook was run in Kaggle.
* [topic_modeling.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/topic_modeling.ipynb): Notebook for topic modelling using BERTopic. This Notebook was run in Kaggle.

**Notebooks for Review Generation:**
* [gpt-2_review_generation.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/gpt-2_review_generation.ipynb): Notebook for generating synthetic product reviews using GPT-2 Medium and calculating perplexity. This Notebook was run in Kaggle.
* [llama-3_review_generation.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/llama-3_review_generation.ipynb): Notebook for generating synthetic product reviews using LLaMA 3 8B and calculating perplexity. Note that the initialization of LLaMA 3 8B in Kaggle with an NVIDIA P100 GPU (16GB) takes roughly 50 minutes and the generation of 10,000 synthetic reviews takes roughly 20 hours.

**Notebooks for Review Analysis:**
* [stat_evaluation.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/stat_evaluation.ipynb): Notebook for the statistical evaluation of the synthetic product reviews, including:
  * Statistical tendencies (Zipf's law)
  * Linguistic features (average length, type-token ratio, verb and noun usage, and readability)
  * MAUVE
  * Inter-rater reliability (for human evaluation)
* [market_analysis_part1.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/market_analysis_part1.ipynb): First Notebook for the market analysis, including:
  * Analysis of manual review classification for market analysis
  * Visualizations of the results
* [market_analysis_part2.ipynb](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Notebooks/market_analysis_part2.ipynb): Second Notebook for the market analysis, including:
  * Sentiment analysis on 10,000 sample of real reviews and both samples of synthetic reviews 
  * Bar chart of the sentiments by review type (Real, GPT-2, LLaMA 3)

## Plots
In the folder [Plots](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/tree/main/Plots) :chart_with_upwards_trend:, we have uploaded all our plots. Below you will find a brief overview of all plots:

**Plots from the Paper:**
* [rating_distribution.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/rating_distribution.pdf): Figure 1 (left side) &ndash; Rating distribution
* [rating_distribution_sentiment.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/rating_distribution_sentiment.pdf): Figure 1 (right side) &ndash; Rating distribution by sentiment
* [wordcloud.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud.pdf): Figure 2 &ndash; Word cloud of all real reviews

**Plots from the Appendix:**
* [hist_rev_len.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/hist_rev_len.pdf): Figure A1 &ndash; Review length distribution
* [wordcloud_pos.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud_pos.pdf): Figure A2 (top) &ndash; Word cloud of reviews classified as positive 
* [worcloud_neg.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud_neg.pdf): Figure A2 (bottom) &ndash; Word cloud of reviews classified as negative
* [wordcloud_rating1.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud_rating1.pdf): Figure A3 (top left) &ndash; Word cloud of reviews with a rating 1/5
* [wordcloud_rating2.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud_rating2.pdf): Figure A3 (top right) &ndash; Word cloud of reviews with a rating 2/5
* [wordcloud_rating3.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud_rating3.pdf): Figure A3 (middle left) &ndash; Word cloud of reviews with a rating 3/5
* [wordcloud_rating4.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud_rating4.pdf): Figure A3 (middle right) &ndash; Word cloud of reviews with a rating 4/5
* [wordcloud_rating5.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/wordcloud_rating5.pdf): Figure A3 (bottom) &ndash; Word cloud of reviews with a rating 5/5
* [real_all_codes.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/real_all_codes.pdf): Figure A4 (top left) &ndash; Distribution of the all codes from the QCA for the real reviews
* [real_main_codes.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/real_main_codes.pdf): Figure A4 (top right) &ndash; Distribution of the main codes from the QCA for the real reviews
* [gpt-2_all_codes.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/gpt-2_all_codes.pdf): Figure A4 (middle left) &ndash; Distribution of the all codes from the QCA for the GPT-2 reviews
* [gpt-2_main_codes.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/gpt-2_main_codes.pdf): Figure A4 (middle right) &ndash; Distribution of the main codes from the QCA for the GPT-2 reviews
* [llama-3_all_codes.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/llama-3_all_codes.pdf): Figure A4 (bottom left) &ndash; Distribution of the all codes from the QCA for the LLaMA 3 reviews
* [llama-3_main_codes.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/llama-3_main_codes.pdf): Figure A4 (bottom right) &ndash; Distribution of the main codes from the QCA for the LLaMA 3 reviews
* [sentiment_distribution_review_types.pdf](https://github.com/TomSOWI/DLSS-24-Synthetic-Product-Reviews-Generation/blob/main/Plots/sentiment_distribution_review_types.pdf): Figure A5 &ndash; Distribution of sentiment by review type (Real, GPT-2, LLaMA 3)
