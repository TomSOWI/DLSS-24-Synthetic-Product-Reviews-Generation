{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-08T21:56:25.989938Z","iopub.status.busy":"2024-07-08T21:56:25.989537Z","iopub.status.idle":"2024-07-08T21:57:15.018090Z","shell.execute_reply":"2024-07-08T21:57:15.016823Z","shell.execute_reply.started":"2024-07-08T21:56:25.989909Z"},"trusted":true},"source":["# **Sentiment analysis**\n","\n","This Notebook performs sentiment analysis based on our checkpoint1.parquet (see [here](https://T34278926.quickconnect.to/d/s/zpVAefWwFEYfIhTRTc0RfJ1h4rXzh6kJ/7VRz2eFaGxxjR11Xtygq65lAszhLPaIi-7LuAL9qlnQs)) using SiEBERT, a fine-tuned RoBERTa large model (see [here](https://huggingface.co/siebert/sentiment-roberta-large-english))\n","\n","Note that this Notebook has been run in Kaggle and some code, such as the loading of the data, will have to be changed if you run this Notebook outside of Kaggle.\n","\n","## Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import necessary packages\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","import numpy as np \n","import pandas as pd \n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, set_seed\n","\n","# Set seed for reproducible and consistent results\n","set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define file paths (Note: must be changed!)\n","input = \"kaggle_environment_input_path\" # change input (4 different split files in total)\n","output = \"senti_split_11.parquet\" # change output (4 different split files in total)\n","\n","# Load the data\n","df = pd.read_parquet(input)"]},{"cell_type":"markdown","metadata":{},"source":["## Load the Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the model\n","checkpoint = 'siebert/sentiment-roberta-large-english'\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"]},{"cell_type":"markdown","metadata":{},"source":["## Define a dataset class"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define dataset class\n","class SentimentDataset(Dataset):\n","    def __init__(self, texts, tokenizer, max_length=512):\n","        self.texts = texts\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=self.max_length)\n","        return inputs"]},{"cell_type":"markdown","metadata":{},"source":["## Run the sentiment analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Move the model to the GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","model.to(device)\n","model.eval() # Set the model to evaluation mode\n","\n","# Create a Dataset and DataLoader\n","texts = df['text'].copy()\n","dataset = SentimentDataset(texts, tokenizer)\n","dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n","\n","predictions = []\n","\n","with torch.no_grad():\n","    # Wrap the dataloader with tqdm to track progress\n","    for batch in tqdm(dataloader, desc=\"Classifying\"):\n","        # Move batch data to GPU\n","        inputs = {key: val.squeeze(1).to(device) for key, val in batch.items()}\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        batch_predictions = torch.argmax(logits, dim=1).tolist()\n","        predictions.extend(batch_predictions)\n","\n","print(\"Classification complete.\")"]},{"cell_type":"markdown","metadata":{},"source":["## Save the data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Add predictions to DataFrame\n","df['label'] = predictions\n","df.to_parquet(output)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5356937,"sourceId":8909238,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
